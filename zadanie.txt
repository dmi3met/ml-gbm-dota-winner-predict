Dota 2 — многопользовательская компьютерная игра жанра MOBA. Игроки играют между
 собой матчи. В каждом матче, как правило, участвует 10 человек. Матчи
 формируются из живой очереди, с учётом уровня игры всех игроков. Перед началом
 игры игроки автоматически разделяются на две команды по пять человек. Одна
 команда играет за светлую сторону (The Radiant), другая — за тёмную (The Dire).
  Цель каждой команды — уничтожить главное здание базы противника, трон.

Вам нужно построить модель, которая по данным о первых пяти минутах матча будет
предсказывать его исход — то есть определять команду-победителя.

Чтобы выполнить это задание, вам необходимо провести ряд исследований, сравнить
несколько алгоритмов машинного обучения и проверить эффект от ряда манипуляций с
 признаками. Также, если вам понравится работать с этими данными, вы можете
 принять участие в соревновании на Kaggle и сравнить свои навыки с другими
 участниками курса!

К заданию приложены следующие файлы:

final-statement.ipynb и final-statement.html — постановка задачи, описание
данных, инструкции по выполнению features.zip — архив с обучающей выборкой
features_test.zip — архив с тестовой выборкой data.zip — полный архив с сырыми
данными и скриптом для извлечения признаков (этот архив понадобится вам только
для участия в kaggle; для выполнения данного задания он не нужен)
extract_features.py — скрипт, извлекающий признаки из сырых данных

Вам необходимо провести описанные в документе final-statement.html (или
final-statement.ipynb) два этапа исследования (для двух подходов к решению
задачи), написать по результатам каждого этапа небольшой отчет (ниже указаны
вопросы, ответы на которые должны содержаться в отчете), и предоставить для
ревью данный отчет и код, с помощью которого вы выполнили задание.

Не забывайте, что в выборке есть признаки, которые "заглядывают в будущее" — они
 помечены в описании данных как отсутствующие в тестовой выборке. Их прямое
 использование в модели приведет к переобучению, поэтому не забудьте исключить
 их из выборки.

Подход 1: градиентный бустинг "в лоб"

Один из самых универсальных алгоритмов, изученных в нашем курсе, является
градиентный бустинг. Он не очень требователен к данным, восстанавливает
нелинейные зависимости, и хорошо работает на многих наборах данных, что и
обуславливает его популярность. В данном разделе предлагается попробовать
градиентный бустинг для решения нашей задачи.

В отчете по данному этапу должны содержаться ответы на следующие вопросы:

Какие признаки имеют пропуски среди своих значений (приведите полный список имен
 этих признаков)? Что могут означать пропуски в этих признаках (ответьте на этот
  вопрос для двух любых признаков)? Как называется столбец, содержащий целевую
  переменную? Как долго проводилась кросс-валидация для градиентного бустинга с
  30 деревьями? Инструкцию по измерению времени можно найти выше по тексту.
  Какое качество при этом получилось? Имеет ли смысл использовать больше 30
  деревьев в градиентном бустинге? Что можно сделать, чтобы ускорить его
  обучение при увеличении количества деревьев?

Подход 2: логистическая регрессия

Линейные методы работают гораздо быстрее композиций деревьев, поэтому кажется
разумным воспользоваться именно ими для ускорение анализа данных. Одним из
наиболее распространенных методов для классификации является логистическая
регрессия. В данном разделе предлгается применить ее к данным, а также
попробовать различные манипуляции с признаками.

В отчете по данному этапу должны содержаться ответы на следующие вопросы:

Какое качество получилось у логистической регрессии над всеми исходными
признаками? Как оно соотносится с качеством градиентного бустинга? Чем можно
объяснить эту разницу? Быстрее ли работает логистическая регрессия по сравнению
с градиентным бустингом? Как влияет на качество логистической регрессии удаление
 категориальных признаков (укажите новое значение метрики качества)? Чем можно
 объяснить это изменение? Сколько различных идентификаторов героев существует в
 данной игре? Какое получилось качество при добавлении "мешка слов" по героям?
 Улучшилось ли оно по сравнению с предыдущим вариантом? Чем можно это объяснить?
  Какое минимальное и максимальное значение прогноза на тестовой выборке
  получилось у лучшего из алгоритмов? Следует понимать, что конкретные
  показатели метрик качества могут отличаться в зависимости от конкретных
  разбиений выборки, значений параметров и версий библиотек. Ответы следует
  проверять на адекватность — в правильную ли сторону изменяется показатель
  качества при том или ином изменении модели или выборки, корректные ли выводы
  делаются из соответствующих результатов.


  Руководство по решению
Вам необходимо провести описанные ниже два этапа исследования, написать по результатам каждого этапа небольшой отчет (ниже указаны вопросы, ответы на которые должны содержаться в отчете), и предоставить для ревью данный отчет и код, с помощью которого вы выполнили задание.

Обратите внимание: высокое качество работы на кросс-валидации (близкое к 100%) — это в первую очередь повод задуматься о том, правильно ли вы обучаете модель. Возможно, вы заглядываете в будущее или настраиваетесь на неправильном наборе признаков.

Подход 1: градиентный бустинг "в лоб"
Один из самых универсальных алгоритмов, изученных в нашем курсе, является градиентный бустинг. Он не очень требователен к данным, восстанавливает нелинейные зависимости, и хорошо работает на многих наборах данных, что и обуславливает его популярность. Вполне разумной мыслью будет попробовать именно его в первую очередь.

Считайте таблицу с признаками из файла features.csv с помощью кода, приведенного выше. Удалите признаки, связанные с итогами матча (они помечены в описании данных как отсутствующие в тестовой выборке).
Проверьте выборку на наличие пропусков с помощью функции count(), которая для каждого столбца показывает число заполненных значений. Много ли пропусков в данных? Запишите названия признаков, имеющих пропуски, и попробуйте для любых двух из них дать обоснование, почему их значения могут быть пропущены.
Замените пропуски на нули с помощью функции fillna(). На самом деле этот способ является предпочтительным для логистической регрессии, поскольку он позволит пропущенному значению не вносить никакого вклада в предсказание. Для деревьев часто лучшим вариантом оказывается замена пропуска на очень большое или очень маленькое значение — в этом случае при построении разбиения вершины можно будет отправить объекты с пропусками в отдельную ветвь дерева. Также есть и другие подходы — например, замена пропуска на среднее значение признака. Мы не требуем этого в задании, но при желании попробуйте разные подходы к обработке пропусков и сравните их между собой.
Какой столбец содержит целевую переменную? Запишите его название.
Забудем, что в выборке есть категориальные признаки, и попробуем обучить градиентный бустинг над деревьями на имеющейся матрице "объекты-признаки". Зафиксируйте генератор разбиений для кросс-валидации по 5 блокам (KFold), не забудьте перемешать при этом выборку (shuffle=True), поскольку данные в таблице отсортированы по времени, и без перемешивания можно столкнуться с нежелательными эффектами при оценивании качества. Оцените качество градиентного бустинга (GradientBoostingClassifier) с помощью данной кросс-валидации, попробуйте при этом разное количество деревьев (как минимум протестируйте следующие значения для количества деревьев: 10, 20, 30). Долго ли настраивались классификаторы? Достигнут ли оптимум на испытанных значениях параметра n_estimators, или же качество, скорее всего, продолжит расти при дальнейшем его увеличении?
Что указать в отчете
В отчете по данному этапу вы должны ответить на следующие вопросы:

Какие признаки имеют пропуски среди своих значений? Что могут означать пропуски в этих признаках (ответьте на этот вопрос для двух любых признаков)?
Как называется столбец, содержащий целевую переменную?
Как долго проводилась кросс-валидация для градиентного бустинга с 30 деревьями? Инструкцию по измерению времени можно найти ниже по тексту. Какое качество при этом получилось? Напомним, что в данном задании мы используем метрику качества AUC-ROC.
Имеет ли смысл использовать больше 30 деревьев в градиентном бустинге? Что бы вы предложили делать, чтобы ускорить его обучение при увеличении количества деревьев?
Рекомендации и советы
Если все работает очень медлено:
Используйте для обучения и кросс-валидации не всю выборку, а некоторое ее подмножество — например, половину объектов. Подмножество лучше всего брать случайным, а не формировать его из первых m объектов.
Попробуйте упростить модель — например, уменьшить глубину деревьев в градиентом бустинге (max_depth).
Измерение времени работы кода
import time
import datetime

start_time = datetime.datetime.now()

time.sleep(3) # вместо этой строчки разместить замеряемый код

print 'Time elapsed:', datetime.datetime.now() - start_time
Подход 2: логистическая регрессия
Линейные методы работают гораздо быстрее композиций деревьев, поэтому кажется разумным воспользоваться именно ими для ускорения анализа данных. Одним из наиболее распространенных методов для классификации является логистическая регрессия.

Важно: не забывайте, что линейные алгоритмы чувствительны к масштабу признаков! Может пригодиться sklearn.preprocessing.StandartScaler.

Оцените качество логистической регрессии (sklearn.linear_model.LogisticRegression с L2-регуляризацией) с помощью кросс-валидации по той же схеме, которая использовалась для градиентного бустинга. Подберите при этом лучший параметр регуляризации (C). Какое наилучшее качество у вас получилось? Как оно соотносится с качеством градиентного бустинга? Чем вы можете объяснить эту разницу? Быстрее ли работает логистическая регрессия по сравнению с градиентным бустингом?
Среди признаков в выборке есть категориальные, которые мы использовали как числовые, что вряд ли является хорошей идеей. Категориальных признаков в этой задаче одиннадцать: lobby_type и r1_hero, r2_hero, ..., r5_hero, d1_hero, d2_hero, ..., d5_hero. Уберите их из выборки, и проведите кросс-валидацию для логистической регрессии на новой выборке с подбором лучшего параметра регуляризации. Изменилось ли качество? Чем вы можете это объяснить?
На предыдущем шаге мы исключили из выборки признаки rM_hero и dM_hero, которые показывают, какие именно герои играли за каждую команду. Это важные признаки — герои имеют разные характеристики, и некоторые из них выигрывают чаще, чем другие. Выясните из данных, сколько различных идентификаторов героев существует в данной игре (вам может пригодиться фукнция unique или value_counts).
Воспользуемся подходом "мешок слов" для кодирования информации о героях. Пусть всего в игре имеет N различных героев. Сформируем N признаков, при этом i-й будет равен нулю, если i-й герой не участвовал в матче; единице, если i-й герой играл за команду Radiant; минус единице, если i-й герой играл за команду Dire. Ниже вы можете найти код, который выполняет данной преобразование. Добавьте полученные признаки к числовым, которые вы использовали во втором пункте данного этапа.
Проведите кросс-валидацию для логистической регрессии на новой выборке с подбором лучшего параметра регуляризации. Какое получилось качество? Улучшилось ли оно? Чем вы можете это объяснить?
Постройте предсказания вероятностей победы команды Radiant для тестовой выборки с помощью лучшей из изученных моделей (лучшей с точки зрения AUC-ROC на кросс-валидации). Убедитесь, что предсказанные вероятности адекватные — находятся на отрезке [0, 1], не совпадают между собой (т.е. что модель не получилась константной).
Что указать в отчете
В отчете по данному этапу вы должны ответить на следующие вопросы:

Какое качество получилось у логистической регрессии над всеми исходными признаками? Как оно соотносится с качеством градиентного бустинга? Чем вы можете объяснить эту разницу? Быстрее ли работает логистическая регрессия по сравнению с градиентным бустингом?
Как влияет на качество логистической регрессии удаление категориальных признаков (укажите новое значение метрики качества)? Чем вы можете объяснить это изменение?
Сколько различных идентификаторов героев существует в данной игре?
Какое получилось качество при добавлении "мешка слов" по героям? Улучшилось ли оно по сравнению с предыдущим вариантом? Чем вы можете это объяснить?
Какое минимальное и максимальное значение прогноза на тестовой выборке получилось у лучшего из алгоритмов?
Код для формирования "мешка слов" по героям
# N — количество различных героев в выборке
X_pick = np.zeros((data.shape[0], N))

for i, match_id in enumerate(data.index):
    for p in xrange(5):
        X_pick[i, data.ix[match_id, 'r%d_hero' % (p+1)]-1] = 1
        X_pick[i, data.ix[match_id, 'd%d_hero' % (p+1)]-1] = -1
Проверка финальной модели
После того как вы провели все эксперименты и выбрали лучшую модель, можете проверить ее качество на тестовых матчах. Выборка тестовых матчей собрана в файле matches_test.jsonlines.bz2. В отличие от основного набора матчей, в тестовых матчах есть только та информация, которая известна на момент первых 5 игровых минут, результат матча — неизвестен. Таблица признаков для тестовых матчей — features_test.csv.

Для всех матчей из тестового набора предскажите вероятность победы Radiant, запишите предсказания в CSV файл с колонками match_id (идентификатор матча) и radiant_win — предсказанная вероятность. Файл с предсказаниями должен выглядеть примерно следующим образом:

match_id,radiant_win
1,0.51997370502
4,0.51997370502
15,0.51997370502
...
Отправьте решение на Kaggle в соревнование: Dota 2: Win Probability Prediction.


Что еще попробовать?
Разумеется, можно попробовать еще очень много разных идей, которые помогут вам получить еще более высокий результат на kaggle. Вот лишь несколько возможных вариантов:

Про каждого из игроков есть достаточно много показателей: максимальный опыт, число смертей и т.д. (см. список выше). Можно попробовать просуммировать или усредних их, получив агрегированные показатели для всей команды.
В сырых данных (файл matches.jsonlines.bz2) содержится очень много информации, которую мы пока не использовали. Вы можете, например, составить "мешки слов" для покупок различных предметов (то есть кодировать информацию о том, сколько раз каждая команда покупала тот или иной предмет). Обратите внимание, что при этом вы можете получить слишком большое количество признаков, для которых может иметь смысл сделать понижение размерности с помощью метода главных компонент.
Можно сформировать признаки про изменения способностей героев в течение матча (ability_upgrades).
В этом задании используются только градиентный бустинг и логистическая регрессия — но ведь мы изучали и другие модели! Можно попробовать метод k ближайших соседей, SVM, случайный лес и так далее.

Задание слишком простое. Что еще можно сделать?
Ответить на вопрос: какое минимальное число минут матча необходимо знать, для того чтобы в 80% матчей верно угадывать победившую сторону? А с точностью 90%? Дайте свой ответ на этот вопрос и докажите что такой точности действительно можно достичь, построив модель и качественно провалидировав ее. Насколько матчи в игре Dota 2 предсказуемы?

Напишите об этом статью, расскажите всем, и приходите к нам на собеседование.